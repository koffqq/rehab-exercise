{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koffqq/rehab-exercise/blob/main/course_ai_rehab_hc_2024_tutorial_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHXNj-m4Ghwm"
      },
      "source": [
        "## **Classification Metrics (Binary)**\n",
        "\n",
        "### 1. **Confusion Matrix**\n",
        "\n",
        "A **Confusion Matrix** is a summary of prediction results that compares the actual (true) labels to the predicted labels made by a classifier. It provides insights into the number of true positives, false positives, true negatives, and false negatives.\n",
        "\n",
        "|                   | **Predicted Positive** | **Predicted Negative** |\n",
        "|-------------------|------------------------|------------------------|\n",
        "| **True Positive**  | **TP**                 | **FN**                 |\n",
        "| **True Negative**  | **FP**                 | **TN**                 |\n",
        "\n",
        "Where:\n",
        "- **TP** = True Positives (truely predicted positive cases),\n",
        "- **FP** = False Positives (falsely predicted positive cases),\n",
        "- **FN** = False Negatives (falsely predicted negative cases),\n",
        "- **TN** = True Negatives (truely predicted negative cases).\n",
        "\n",
        "This matrix helps in calculating other metrics like accuracy, precision, recall, F1-score, and specificity.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Accuracy**\n",
        "\n",
        "**Accuracy** measures the percentage of correct predictions out of all predictions.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- **TP** = True Positives,\n",
        "- **TN** = True Negatives,\n",
        "- **FP** = False Positives,\n",
        "- **FN** = False Negatives.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Precision**\n",
        "\n",
        "**Precision** measures the proportion of true positive predictions out of all positive predictions (i.e., how many selected items are relevant).\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "It is useful when the cost of false positives is high (e.g., in spam detection).\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Recall (Sensitivity or True Positive Rate)**\n",
        "\n",
        "**Recall** measures the proportion of actual positive cases that were correctly identified (i.e., how many relevant items are selected).\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "It is important when the cost of false negatives is high (e.g., in medical diagnosis).\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Specificity (True Negative Rate)**\n",
        "\n",
        "**Specificity** measures the proportion of actual negative cases that were correctly identified. It is the complement of recall and focuses on the correct identification of negative cases.\n",
        "\n",
        "$$\n",
        "\\text{Specificity} = \\frac{TN}{TN + FP}\n",
        "$$\n",
        "\n",
        "Specificity is important in scenarios where false positives are costly, such as in medical tests.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Balanced Accuracy**\n",
        "\n",
        "**Balanced Accuracy** adjusts for class imbalance by averaging the accuracy for both the positive and negative classes.\n",
        "\n",
        "$$\n",
        "\\text{Balanced Accuracy} = \\frac{1}{2} \\left( \\frac{TP}{TP + FN} + \\frac{TN}{TN + FP} \\right)\n",
        "$$\n",
        "\n",
        "This is particularly useful when working with imbalanced datasets, as it gives equal weight to the positive and negative classes.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **F1-Score**\n",
        "\n",
        "**F1-Score** is the harmonic mean of precision and recall, providing a single metric that balances both.\n",
        "\n",
        "$$\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "F1-Score is useful when you need a balance between precision and recall.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **ROC-AUC Score**\n",
        "\n",
        "**ROC (Receiver Operating Characteristic)** curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold (probability threshold to output positive) is varied.\n",
        "\n",
        "- **AUC (Area Under Curve)** is the area under the ROC curve and provides a single value to compare different models (a higher AUC means the model is more robust and its good performance does not vary a lot by changing the threshold).\n",
        "\n",
        "The **True Positive Rate (TPR)** and **False Positive Rate (FPR)** are used to plot the ROC curve:\n",
        "\n",
        "$$\n",
        "\\text{TPR} = \\frac{TP}{TP + FN}, \\quad \\text{FPR} = \\frac{FP}{FP + TN}\n",
        "$$\n",
        "<br>\n",
        "\n",
        "A perfect model has an AUC of 1, while a random classifier has an AUC of 0.5 (assuming binary and balanced classes), because it represents the performance of a **random classifier**. Here's why:\n",
        "\n",
        "##### 1. **Random Guessing**:\n",
        "   - A **random classifier** does not have any discriminative ability; it essentially guesses the class label randomly, with a 50/50 chance for binary classification (assuming balanced classes).\n",
        "   - This means that the classifier will predict positive and negative labels in a completely unstructured manner.\n",
        "\n",
        "##### 2. **ROC Curve for a Random Classifier**:\n",
        "   - A random classifier would have an equal chance of making correct and incorrect predictions, leading to a **True Positive Rate (TPR)** that is proportional to the **False Positive Rate (FPR)**.\n",
        "   - In this case, the ROC curve is a diagonal line from the bottom-left (0, 0) to the top-right (1, 1), indicating that as the threshold changes, the TPR and FPR increase at the same rate. This is essentially a 50% chance of being correct.\n",
        "\n",
        "##### 3. **AUC for a Random Classifier**:\n",
        "   - The **AUC** measures the area under the ROC curve. For a random classifier, the ROC curve is the diagonal line, and the area under this line is exactly **0.5**.\n",
        "   - An AUC of **0.5** implies that the model has no predictive ability; it is effectively guessing. This is the baseline for comparing other models.\n",
        "\n",
        "##### Why Not Below 0.5?\n",
        "- If a classifier has an **AUC below 0.5**, it means the model is worse than random guessing. In theory, a classifier with an AUC less than 0.5 can be inverted (flipping its predictions), and it would perform better than random guessing (yielding an AUC greater than 0.5).\n",
        "- For example, an AUC of 0.3 means that the classifier systematically predicts incorrectly more often than not. You could swap the predictions (i.e., predict positive where the model predicts negative, and vice versa), and you would get an AUC of **1 - 0.3 = 0.7**, which would indicate a better performance.\n",
        "\n",
        "##### AUC and Model Performance:\n",
        "- **AUC = 0.5**: The model has no discriminative ability (random guessing).\n",
        "- **AUC < 0.5**: The model is worse than random guessing and can be improved by inverting predictions.\n",
        "- **AUC > 0.5**: The model is better than random guessing, with higher values indicating better performance.\n",
        "- **AUC = 1.0**: A perfect classifier, with no false positives and no false negatives.\n",
        "\n",
        "In summary, the minimum AUC of **0.5** reflects the performance of a random classifier because it cannot do any better than randomly guessing the outcomes of positive or negative classes. This is the baseline against which the discriminative ability of other models is measured.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Precision-Recall Curve (PR-curve)**\n",
        "\n",
        "The **Precision-Recall Curve (PR-curve)** is a graphical representation that shows the trade-off between **precision** and **recall** for different threshold values in a classification model, particularly useful when dealing with **imbalanced datasets**. Hereâ€™s a detailed explanation:\n",
        "\n",
        "\n",
        "\n",
        "### What the PR-Curve Shows:\n",
        "- The **Precision-Recall Curve** plots **precision** on the Y-axis and **recall** on the X-axis for different threshold values.\n",
        "- As the threshold for classifying an instance as positive changes, the values of precision and recall will change.\n",
        "  - When the threshold is lowered, more instances are classified as positive, leading to higher recall but often lower precision because of more false positives.\n",
        "  - When the threshold is raised, fewer instances are classified as positive, leading to higher precision but lower recall.\n",
        "\n",
        "### Why the PR-Curve is Useful:\n",
        "- **Imbalanced Datasets**: The PR-curve is particularly valuable when dealing with imbalanced datasets where the number of positive instances is much smaller than the negative instances. In such cases, **accuracy** and even the **ROC curve** can be misleading.\n",
        "  - For example, in a dataset where 95% of the data is negative, a classifier can achieve high accuracy by predicting everything as negative. However, the PR-curve focuses on the performance for the minority class (positive class).\n",
        "  \n",
        "- **Trade-off between Precision and Recall**: It shows how well the model performs in balancing precision and recall, which is crucial in scenarios where you need to optimize one over the other. For instance:\n",
        "  - In **spam detection**, you might want higher precision (to avoid labeling legitimate emails as spam).\n",
        "  - In **medical diagnostics**, you might prioritize recall (to minimize false negatives and ensure sick patients are identified).\n",
        "\n",
        "### Interpretation of the PR-Curve:\n",
        "- A good model will maintain high precision while recall increases, meaning the curve will be pushed towards the top-right corner.\n",
        "- A **baseline** model would produce a horizontal line representing the proportion of positive examples in the dataset. If your modelâ€™s PR curve is above this line, it is performing better than random guessing.\n",
        "\n",
        "### Comparison with the ROC Curve:\n",
        "- **ROC Curve**: The ROC curve plots **True Positive Rate (TPR)** (recall) against **False Positive Rate (FPR)**, and itâ€™s useful when you care about both classes equally. However, the ROC curve can be misleading when classes are highly imbalanced because it includes FPR, which is not very informative when negatives dominate the dataset.\n",
        "  \n",
        "- **PR Curve**: The PR-curve only focuses on the positive class, and it is more informative than the ROC curve in scenarios where:\n",
        "  - You are working with imbalanced data.\n",
        "  - You care more about the performance of the positive class (e.g., fraud detection, rare disease detection).\n",
        "  \n",
        "### Area Under the PR-Curve (AUC-PR):\n",
        "- Similar to the ROC curve, the **Area Under the Precision-Recall Curve (AUC-PR)** can be used to summarize the modelâ€™s performance.\n",
        "  - **AUC-PR = 1.0**: Perfect classifier (high precision and recall at all thresholds).\n",
        "  - **AUC-PR near 0**: Poor classifier.\n",
        "  - **AUC-PR closer to the baseline**: Indicates a model that is close to random guessing.\n",
        "\n",
        "### Example:\n",
        "In a dataset where you are detecting fraudulent transactions (rare positives), the PR curve can tell you how much you will sacrifice in precision as you increase recall. This trade-off is critical because in such a case, you may want to balance precision and recall differently depending on the application (e.g., minimizing false positives vs. catching as many fraud cases as possible).\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Log-Loss**\n",
        "\n",
        "**Log-Loss**, also known as **Logarithmic Loss** or **Binary Cross-Entropy**, is a performance metric that evaluates the accuracy of probabilistic predictions for a binary classification model. Unlike simpler metrics like accuracy, log-loss takes into account the predicted probability of each class and penalizes incorrect classifications more harshly.\n",
        "\n",
        "The formula for log-loss is:\n",
        "\n",
        "$$\n",
        "\\text{Log-Loss} = - \\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $(n)$ is the number of data points.\n",
        "- $(y_i)$ is the actual label (0 or 1).\n",
        "- $(p_i)$ is the predicted probability for the positive class (between 0 and 1).\n",
        "\n",
        "### Key Points:\n",
        "- **Log-Loss** measures how well a modelâ€™s predicted probabilities match the actual outcomes.\n",
        "- **Lower log-loss** values are better, as it indicates that the predicted probabilities are closer to the true labels.\n",
        "  - **Log-Loss = 0**: Perfect predictions (the model predicts 1 with 100% certainty when the true label is 1, and similarly for 0).\n",
        "  - **Log-Loss approaches infinity**: The model is confidently wrong (e.g., predicting a probability of 1 when the true label is 0).\n",
        "\n",
        "#### Why Log-Loss is Important:\n",
        "\n",
        "1. **Probabilistic Predictions**:\n",
        "   - Unlike accuracy, precision, or recall, which only evaluate hard class predictions (0 or 1), log-loss evaluates the **quality of the predicted probabilities**.\n",
        "   - In many real-world applications, knowing the probability of an event is just as important as the predicted class. For example, in medical diagnostics or financial risk assessments, you may want to understand the confidence level of predictions (e.g., 80% chance of a disease vs. 55% chance).\n",
        "\n",
        "2. **Capturing Confidence**:\n",
        "   - Log-loss penalizes **overconfident wrong predictions** much more heavily than predictions that are closer to the correct probability. For example:\n",
        "     - Predicting 0.99 when the true label is 1 leads to a small penalty.\n",
        "     - Predicting 0.01 when the true label is 1 leads to a much larger penalty.\n",
        "   - This characteristic encourages models to be cautious and avoid making extremely confident incorrect predictions.\n",
        "\n",
        "3. **Handling Imbalanced Classes**:\n",
        "   - In **imbalanced datasets**, accuracy can be misleading because a model might perform well by always predicting the majority class. However, log-loss takes into account the confidence of the model's predictions, providing a more nuanced assessment of performance, especially for the minority class.\n",
        "\n",
        "4. **Continuous Evaluation**:\n",
        "   - Since log-loss evaluates the predicted probabilities rather than the final binary classification, it provides more detailed feedback during model training. It can guide model tuning by revealing how confident and correct the model is on average.\n",
        "\n",
        "5. **Penalizes Misclassification**:\n",
        "   - Log-loss penalizes false predictions more harshly than correct predictions. If a model is unsure about a prediction (e.g., predicting a probability close to 0.5), the penalty is less severe compared to confidently making an incorrect prediction.\n",
        "\n",
        "### Example:\n",
        "Consider a binary classification task, and you have the following predictions:\n",
        "\n",
        "| Actual | Predicted Probability |\n",
        "|--------|-----------------------|\n",
        "| 1      | 0.9                   |\n",
        "| 0      | 0.2                   |\n",
        "| 1      | 0.6                   |\n",
        "| 0      | 0.8                   |\n",
        "\n",
        "- For the first prediction, the model is confident (0.9) and correct, so the log-loss will be small.\n",
        "- For the last prediction, the model is confident but wrong (0.8 when the true label is 0), so the log-loss will be large.\n",
        "\n",
        "This shows how log-loss differentiates between predictions that are confident and wrong versus predictions that are uncertain.\n",
        "\n",
        "### Why is Log-Loss Preferable in Some Cases?\n",
        "\n",
        "- **Probability-Sensitive**: Log-loss cares about how confident the model is in its predictions, which is crucial when working with probabilistic predictions. For instance, if you want your model to provide insights into how likely a certain event is (e.g., fraud detection, medical diagnosis), log-loss will penalize overconfidence in wrong predictions.\n",
        "  \n",
        "- **Model Calibration**: Log-loss helps in assessing how well-calibrated a model is. A well-calibrated model will output probabilities that reflect the true likelihood of events. For example, if a model predicts a 0.7 probability for 100 events, about 70 of those events should be positive.\n",
        "\n",
        "### When to Use Log-Loss:\n",
        "\n",
        "- **Classification problems with imbalanced data** where you need to account for the confidence of predictions.\n",
        "- **Applications requiring probabilistic predictions** rather than hard classifications, such as financial risk models, medical diagnosis, or weather prediction.\n",
        "- **When you need a metric that penalizes confident misclassifications**, which encourages models to be careful when predicting probabilities.\n",
        "\n",
        "In summary, **log-loss** is important because it evaluates the quality of probabilistic predictions and penalizes overconfident wrong predictions, providing a more nuanced and useful measure for tasks where understanding prediction probabilities is critical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfOkygy7Hjpd"
      },
      "source": [
        "\n",
        "# **Classification Metrics (Multiclass)**\n",
        "\n",
        "### 1. **Confusion Matrix (Multiclass)**\n",
        "\n",
        "In a **multiclass confusion matrix**, the rows represent the actual classes, and the columns represent the predicted classes. Instead of just two classes (positive and negative), each class has its own row and column.\n",
        "\n",
        "|                   | **Predicted Class 1** | **Predicted Class 2** | **...** | **Predicted Class N** |\n",
        "|-------------------|-----------------------|-----------------------|--------|-----------------------|\n",
        "| **True Class 1**   | **TP for Class 1**    | **FP for Class 1**     | ...    |                       |\n",
        "| **True Class 2**   | **FN for Class 2**    | **TP for Class 2**     | ...    |                       |\n",
        "| **...**           |                       |                       | ...    |                       |\n",
        "| **True Class N**   |                       |                       |        | **TP for Class N**    |\n",
        "\n",
        "- **True Positives (TP)**: Correctly predicted instances for each class.\n",
        "- **False Positives (FP)**: Instances incorrectly predicted as a particular class.\n",
        "- **False Negatives (FN)**: Instances of a class that were incorrectly predicted as another class.\n",
        "- **True Negatives (TN)** are generally calculated for each class by summing all the instances not in that class.\n",
        "\n",
        "This matrix helps in calculating other multiclass metrics like precision, recall, F1-score, and accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Accuracy (Multiclass)**\n",
        "\n",
        "In the multiclass case, **accuracy** still measures the proportion of correct predictions out of all predictions, regardless of the class.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Total Correct Predictions}}{\\text{Total Predictions}}\n",
        "$$\n",
        "\n",
        "Where **Total Correct Predictions** is the sum of the diagonal elements of the confusion matrix (all true positives).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Precision (Multiclass)**\n",
        "\n",
        "For multiclass problems, **precision** can be calculated in three ways:\n",
        "\n",
        "- **Macro-averaged Precision**: Precision is calculated for each class separately and then averaged equally, treating all classes equally.\n",
        "  \n",
        "  $$\n",
        "  \\text{Macro Precision} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{TP_i}{TP_i + FP_i}\n",
        "  $$\n",
        "\n",
        "- **Weighted Precision**: Precision is calculated for each class and then weighted by the number of true instances in each class to account for class imbalance.\n",
        "  \n",
        "  $$\n",
        "  \\text{Weighted Precision} = \\sum_{i=1}^{N} \\frac{n_i}{n} \\cdot \\frac{TP_i}{TP_i + FP_i}\n",
        "  $$\n",
        "\n",
        "- **Micro-averaged Precision**: Treats all classes as a single binary classification problem by summing the **TP**, **FP**, and **FN** across all classes:\n",
        "  \n",
        "  $$\n",
        "  \\text{Micro Precision} = \\frac{\\sum TP}{\\sum (TP + FP)}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Recall (Sensitivity or True Positive Rate) (Multiclass)**\n",
        "\n",
        "Similarly, recall can be computed in three ways:\n",
        "\n",
        "- **Macro-averaged Recall**: Calculated by averaging the recall for each class equally:\n",
        "  \n",
        "  $$\n",
        "  \\text{Macro Recall} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{TP_i}{TP_i + FN_i}\n",
        "  $$\n",
        "\n",
        "- **Weighted Recall**: Adjusts for the number of true instances in each class:\n",
        "  \n",
        "  $$\n",
        "  \\text{Weighted Recall} = \\sum_{i=1}^{N} \\frac{n_i}{n} \\cdot \\frac{TP_i}{TP_i + FN_i}\n",
        "  $$\n",
        "\n",
        "- **Micro-averaged Recall**: Treats all classes as a single binary classification problem by summing the **TP**, **FP**, and **FN** across all classes:\n",
        "  \n",
        "  $$\n",
        "  \\text{Micro Recall} = \\frac{\\sum TP}{\\sum (TP + FN)}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Specificity (True Negative Rate) (Multiclass)**\n",
        "\n",
        "For multiclass classification, **specificity** is calculated for each class by treating it as a binary classification (this class vs. all others):\n",
        "\n",
        "$$\n",
        "\\text{Specificity for Class i} = \\frac{TN_i}{TN_i + FP_i}\n",
        "$$\n",
        "\n",
        "Similar to precision and recall, you can compute **macro-averaged specificity** (equal weight for each class) or **weighted specificity** (weighted by class size).\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Balanced Accuracy (Multiclass)**\n",
        "\n",
        "**Balanced Accuracy** is particularly useful for imbalanced datasets in multiclass problems. It is calculated by averaging the recall (sensitivity) for each class, giving equal importance to each class, regardless of class size.\n",
        "\n",
        "#### **Unweighted Balanced Accuracy**:\n",
        "\n",
        "$$\n",
        "\\text{Balanced Accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{TP_i}{TP_i + FN_i}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ N $ is the total number of classes.\n",
        "- $ TP_i $ is the number of true positives for class $ i $.\n",
        "- $ FN_i $ is the number of false negatives for class $ i $.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Weighted Balanced Accuracy**:\n",
        "\n",
        "\n",
        "$$ {Weighted Balanced Accuracy} = \\sum_{i=1}^{N} w_i \\cdot \\frac{TP_i}{TP_i + FN_i}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ w_i $ is the weight for class $ i $, which is proportional to the number of true samples in class $ i $:\n",
        "  $$\n",
        "  w_i = \\frac{n_i}{n}\n",
        "  $$\n",
        "  Where $ n_i $ is the number of true instances of class $ i $, and $ n $ is the total number of instances across all classes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **F1-Score (Multiclass)**\n",
        "\n",
        "The **F1-Score** can be computed in three ways:\n",
        "\n",
        "- **Macro F1-Score**: The F1-score is calculated for each class separately, and the results are averaged equally.\n",
        "  \n",
        "  $$\n",
        "  \\text{Macro F1} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{2 \\cdot \\text{Precision}_i \\cdot \\text{Recall}_i}{\\text{Precision}_i + \\text{Recall}_i}\n",
        "  $$\n",
        "\n",
        "- **Weighted F1-Score**: Similar to precision and recall, it weighs the F1 score for each class based on the number of true instances in that class:\n",
        "  \n",
        "  $$\n",
        "  \\text{Weighted F1} = \\sum_{i=1}^{N} \\frac{n_i}{n} \\cdot \\frac{2 \\cdot \\text{Precision}_i \\cdot \\text{Recall}_i}{\\text{Precision}_i + \\text{Recall}_i}\n",
        "  $$\n",
        "\n",
        "- **Micro-averaged F1-Score**: In this case, micro-averaged precision and recall are used to compute a single F1-score across all classes. Since micro-averaging sums up the **TP**, **FP**, and **FN** globally, the **micro F1** is also computed globally:\n",
        "  \n",
        "  $$\n",
        "  \\text{Micro F1} = \\frac{2 \\times \\text{Micro Precision} \\times \\text{Micro Recall}}{\\text{Micro Precision} + \\text{Micro Recall}}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of Averages:\n",
        "\n",
        "- **Macro**: Treats each class equally and averages metrics across classes.\n",
        "- **Weighted**: Weighs each class's contribution based on its size.\n",
        "- **Micro**: Sums up the true positives, false positives, and false negatives globally across all classes and treats the problem as a single binary classification.\n",
        "\n",
        "These approaches provide flexibility when evaluating multiclass classifiers, allowing you to emphasize overall performance (micro), treat all classes equally (macro), or account for class imbalance (weighted).\n",
        "\n",
        "### 8. **ROC-AUC for Multiclass**\n",
        "\n",
        "In the multiclass setting, **ROC-AUC** can be computed by considering each class against all other classes (one-vs-rest approach). For each class $i$, we compute the ROC curve, treating class $i$ as the positive class and all others as the negative class.\n",
        "\n",
        "The overall **multiclass AUC** can then be calculated by averaging the AUC scores for all classes.\n",
        "\n",
        "For each class $i$, the **True Positive Rate (TPR)** and **False Positive Rate (FPR)** are defined as:\n",
        "\n",
        "$$\n",
        "\\text{TPR}_i = \\frac{TP_i}{TP_i + FN_i}, \\quad \\text{FPR}_i = \\frac{FP_i}{FP_i + TN_i}\n",
        "$$\n",
        "\n",
        "The **ROC-AUC** is then computed as the area under the ROC curve for each class, and the average AUC can be taken across all classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzC9iS7np5v"
      },
      "source": [
        "# Hyper-parameters (for you)\n",
        "Which k gives the best performance for the following dataset and its split,using a k-NN classifier?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "jrmesFfXPNG7",
        "outputId": "bcdf4536-09da-4c6b-bc82-8747a55df1df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Metric  Score\n",
              "0           Accuracy  76.5%\n",
              "1          Precision  76.6%\n",
              "2             Recall  76.8%\n",
              "3        Specificity  89.2%\n",
              "4  Balanced Accuracy  76.8%\n",
              "5           F1 Score  76.3%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04ce2bf0-7af3-45a0-9768-9d6a1b8a27de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>76.5%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Precision</td>\n",
              "      <td>76.6%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recall</td>\n",
              "      <td>76.8%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Specificity</td>\n",
              "      <td>89.2%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Balanced Accuracy</td>\n",
              "      <td>76.8%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>F1 Score</td>\n",
              "      <td>76.3%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04ce2bf0-7af3-45a0-9768-9d6a1b8a27de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04ce2bf0-7af3-45a0-9768-9d6a1b8a27de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04ce2bf0-7af3-45a0-9768-9d6a1b8a27de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-651a49a3-0a73-4462-bcf9-5910cf7087d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-651a49a3-0a73-4462-bcf9-5910cf7087d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-651a49a3-0a73-4462-bcf9-5910cf7087d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e8ea39ee-df4c-435f-b43e-7ed87195b150\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e8ea39ee-df4c-435f-b43e-7ed87195b150 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics_df",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Accuracy\",\n          \"Precision\",\n          \"F1 Score\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"76.6%\",\n          \"76.3%\",\n          \"76.8%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Modifying the model to K-Nearest Neighbors (KNN)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_classes=5, n_clusters_per_class=2, flip_y=0, random_state=0)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the K-Nearest Neighbors (KNN) model with n_neighbors = {1, 3, 5, 7, 10, 12, 15, 40, 100}\n",
        "model = KNeighborsClassifier(n_neighbors=100)\n",
        "\n",
        "# Predict x_test and calculate all the matrix\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate classification metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average = \"macro\")\n",
        "recall = recall_score(y_test, y_pred, average = \"macro\")\n",
        "specificity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1]) # TN / (TN + FP)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average = \"macro\")\n",
        "\n",
        "# Compile all metrics into a DataFrame\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'Specificity', 'Balanced Accuracy', 'F1 Score'],\n",
        "    'Score': [accuracy, precision, recall, specificity, balanced_accuracy, f1]\n",
        "})\n",
        "# Convert metrics to percentages and round to 1 decimal place\n",
        "metrics_df['Score'] = (metrics_df['Score'] * 100).round(1).astype(str) + '%'\n",
        "\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8r6LXBYOmBg"
      },
      "source": [
        "# (For you)\n",
        "Which k gives the best performance for the following dataset and its cross-validated split,using a k-NN classifier?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VB4pt45PNGz5",
        "outputId": "a3cfa633-6dfa-48a9-a555-7444a2f75324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Metric         Score\n",
              "0           Accuracy  78.4% Â± 1.2%\n",
              "1  Precision (Macro)  78.5% Â± 1.1%\n",
              "2     Recall (Macro)  78.4% Â± 1.2%\n",
              "3         F1 (Macro)  78.4% Â± 1.1%\n",
              "4  Balanced Accuracy  78.4% Â± 1.2%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91ff9000-0508-4fe4-8b17-945151c9bef5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>78.4% Â± 1.2%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Precision (Macro)</td>\n",
              "      <td>78.5% Â± 1.1%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recall (Macro)</td>\n",
              "      <td>78.4% Â± 1.2%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F1 (Macro)</td>\n",
              "      <td>78.4% Â± 1.1%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Balanced Accuracy</td>\n",
              "      <td>78.4% Â± 1.2%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91ff9000-0508-4fe4-8b17-945151c9bef5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91ff9000-0508-4fe4-8b17-945151c9bef5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91ff9000-0508-4fe4-8b17-945151c9bef5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3dd57a44-3c3c-4d94-a6db-79ce9aa53c68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dd57a44-3c3c-4d94-a6db-79ce9aa53c68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3dd57a44-3c3c-4d94-a6db-79ce9aa53c68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b00f77b1-07e0-4de2-a733-7fea4361ffd7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b00f77b1-07e0-4de2-a733-7fea4361ffd7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metrics",
              "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Precision (Macro)\",\n          \"Balanced Accuracy\",\n          \"Recall (Macro)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"78.4% \\u00b1 1.2%\",\n          \"78.5% \\u00b1 1.1%\",\n          \"78.4% \\u00b1 1.1%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Implementing cross-validation for the same example\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_classes=5, n_clusters_per_class=2, flip_y=0, random_state=0)\n",
        "\n",
        "# Set up cross-validation with 5 splits\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# Arrays to store results for each fold\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "balanced_accuracy_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Loop through the cross-validation splits\n",
        "for train_index, test_index in cv.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the K-Nearest Neighbors (KNN) model with n_neighbors = {1, 3, 5, 7, 10, 12, 15, 40, 100}\n",
        "    model = KNeighborsClassifier(n_neighbors=1)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Precision, Recall, F1 (Macro)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Balanced Accuracy\n",
        "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    balanced_accuracy_scores.append(balanced_acc)\n",
        "\n",
        "# Aggregate Results\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "avg_balanced_acc = np.mean(balanced_accuracy_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "std_balanced_acc = np.std(balanced_accuracy_scores)\n",
        "\n",
        "# Display aggregated metrics with mean and standard deviation in formatted style\n",
        "metrics_df = {\n",
        "    'Metric': ['Accuracy', 'Precision (Macro)', 'Recall (Macro)', 'F1 (Macro)', 'Balanced Accuracy'],\n",
        "    'Score': [f\"{(avg_accuracy * 100):.1f}% Â± {(std_accuracy * 100):.1f}%\",\n",
        "              f\"{(avg_precision * 100):.1f}% Â± {(std_precision * 100):.1f}%\",\n",
        "              f\"{(avg_recall * 100):.1f}% Â± {(std_recall * 100):.1f}%\",\n",
        "              f\"{(avg_f1 * 100):.1f}% Â± {(std_f1 * 100):.1f}%\",\n",
        "              f\"{(avg_balanced_acc * 100):.1f}% Â± {(std_balanced_acc * 100):.1f}%\"]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_metrics = pd.DataFrame(metrics_df)\n",
        "\n",
        "df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBG0dzaaRlxY",
        "outputId": "f43d56ac-8299-4ffc-8ce7-64740fe78fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of neighbors (k): 10\n",
            "Best accuracy score: 83.2%\n"
          ]
        }
      ],
      "source": [
        "# Implementing cross-validation with GridSearch for KNN hyperparameter tuning\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_classes=5, n_clusters_per_class=2, flip_y=0, random_state=0)\n",
        "\n",
        "# Set up cross-validation with 5 splits\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# Define the parameter grid for KNeighborsClassifier (range of n_neighbors)\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 10, 12, 15, 40, 100]}\n",
        "\n",
        "# Initialize the KNN model, doesn't learn as bootstrapping classification\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Set up the GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=cv, scoring='accuracy', return_train_score=True)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best hyperparameters and corresponding score\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Output results rounded and converted to percentage\n",
        "best_score_percent = round(best_score * 100, 1)\n",
        "print(f\"Best number of neighbors (k): {best_k}\")\n",
        "print(f\"Best accuracy score: {best_score_percent}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De9nYj9IZaVQ"
      },
      "source": [
        "# Understanding Train, Validation, and Test Data\n",
        "\n",
        "When building machine learning models, it is crucial to divide the dataset into three distinct parts: **training**, **validation**, and **test** sets. These splits help ensure that the model can generalize well to new data and avoid overfitting. Letâ€™s explore the purpose of each one in detail:\n",
        "\n",
        "## 1. **Training Data**\n",
        "The **training data** is the portion of the dataset used to train the model. This is the data the model \"learns\" from by adjusting its internal parameters to minimize the error between predictions and actual labels.\n",
        "\n",
        "### Key Points:\n",
        "- The model has direct access to the training data.\n",
        "- Used for optimizing the modelâ€™s parameters (e.g., the neighbors in k-NN or weights in neural networks).\n",
        "- The performance on the training data should improve as the model learns.\n",
        "\n",
        "### Potential Issue:\n",
        "If the model performs well only on the training data but poorly on new data, it is likely **overfitting**â€”i.e., learning patterns specific to the training data that don't generalize to unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Validation Data**\n",
        "The **validation data** is used during the training process to evaluate the modelâ€™s performance on unseen data. This helps fine-tune the model and make decisions like choosing hyperparameters (e.g., learning rate, number of neighbors in KNN, etc.). Choose or tune k with the (seen) validation data for this specified test. -> and then go to the next test set -> use cross validation.\n",
        "\n",
        "### Key Points:\n",
        "- The model does **not** train on the validation data; it only evaluates performance.\n",
        "- Helps in tuning model hyperparameters.\n",
        "- Used for **early stopping** in some algorithms to prevent overfitting.\n",
        "  \n",
        "### Why It's Needed:\n",
        "If you only rely on training data for evaluating the model, it can lead to an over-optimized model that does not generalize. Validation data acts as a checkpoint to measure how well the model performs on data it hasnâ€™t seen during training.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Test Data**\n",
        "The **test data** is used **only after** the model is fully trained and optimized. This is the final evaluation step to check how well the model performs on completely unseen data.\n",
        "\n",
        "### Key Points:\n",
        "- The test data should only be used **once** for final evaluation.\n",
        "- Provides an unbiased estimate of the modelâ€™s performance on real-world data.\n",
        "- Helps answer the question: **\"How well will this model perform on new data?\"**\n",
        "\n",
        "### Why Separate from Validation Data?\n",
        "The validation set is used multiple times during training for tuning and model selection. Thus, the model can indirectly \"see\" this data, potentially leading to overfitting on the validation set as well. The test set provides an objective, **final evaluation** that the model hasnâ€™t been exposed to before.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **Training Data**: Used to fit the model and learn patterns.\n",
        "- **Validation Data**: Used to fine-tune and select the best model during training.\n",
        "- **Test Data**: Used only after the model is fully trained to evaluate final performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fk1sSzyvgJP"
      },
      "source": [
        "# For you!\n",
        "- Split the data into test and train/validation.<br>\n",
        "- Use Cross Validation and the train/validation data to find the optimal k-nn model.<br>\n",
        "- Use your optimal model and test it on the test data, and report the classification metrics.\n",
        "\n",
        "```python\n",
        "# Splitting the data and creating the grid search object\n",
        "# ...\n",
        "\n",
        "# Finding the optimal hyper-pars for the model\n",
        "grid_search.fit(X_train_valid, y_train_valid)\n",
        "\n",
        "# Testing the optimal model on the test data\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Creating the classification metrics for the test set\n",
        "# ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "tFNxD17Danqb",
        "outputId": "a16729be-d374-476d-bdca-a9b3a83f234f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best number of neighbors (k): 10\n",
            "Best accuracy score: 81.8%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Metric  Score\n",
              "0           Accuracy  82.1%\n",
              "1          Precision  82.1%\n",
              "2             Recall  82.1%\n",
              "3        Specificity  93.4%\n",
              "4  Balanced Accuracy  82.1%\n",
              "5           F1 Score  81.9%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-601d50f1-ffc9-416b-94d0-285660f3d1d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>82.1%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Precision</td>\n",
              "      <td>82.1%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recall</td>\n",
              "      <td>82.1%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Specificity</td>\n",
              "      <td>93.4%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Balanced Accuracy</td>\n",
              "      <td>82.1%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>F1 Score</td>\n",
              "      <td>81.9%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-601d50f1-ffc9-416b-94d0-285660f3d1d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-601d50f1-ffc9-416b-94d0-285660f3d1d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-601d50f1-ffc9-416b-94d0-285660f3d1d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87d54bba-9aae-4597-b9c5-6329142e97ec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87d54bba-9aae-4597-b9c5-6329142e97ec')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87d54bba-9aae-4597-b9c5-6329142e97ec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_509f883c-670a-4479-9acf-ffd63362f6d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_509f883c-670a-4479-9acf-ffd63362f6d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics_df",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Accuracy\",\n          \"Precision\",\n          \"F1 Score\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"82.1%\",\n          \"93.4%\",\n          \"81.9%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Implementing cross-validation with GridSearch for KNN hyperparameter tuning\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_classes=5, n_clusters_per_class=2, flip_y=0, random_state=0)\n",
        "\n",
        "# Split the dataset into training, validation and test sets\n",
        "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up cross-validation with 5 splits\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# Define the parameter grid for KNeighborsClassifier (range of n_neighbors)\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 10, 12, 15, 40, 100]}\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Set up the GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=cv, scoring='accuracy', return_train_score=True)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train_valid, y_train_valid)\n",
        "\n",
        "# Get the best hyperparameters and corresponding score\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Output results rounded and converted to percentage\n",
        "best_score_percent = round(best_score * 100, 1)\n",
        "print(f\"Best number of neighbors (k): {best_k}\")\n",
        "print(f\"Best accuracy score: {best_score_percent}%\")\n",
        "\n",
        "# Testing the optimal model on the test data\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate classification metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average = \"macro\")\n",
        "recall = recall_score(y_test, y_pred, average = \"macro\")\n",
        "specificity = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1]) # TN / (TN + FP)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average = \"macro\")\n",
        "\n",
        "# Compile all metrics into a DataFrame\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'Specificity', 'Balanced Accuracy', 'F1 Score'],\n",
        "    'Score': [accuracy, precision, recall, specificity, balanced_accuracy, f1]\n",
        "})\n",
        "# Convert metrics to percentages and round to 1 decimal place\n",
        "metrics_df['Score'] = (metrics_df['Score'] * 100).round(1).astype(str) + '%'\n",
        "\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgmKe6WDx5v8"
      },
      "source": [
        "# (For you) Everything in a Cross Validation loop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ATMYP-Vwx3zX",
        "outputId": "262685de-087f-4fff-91cf-d4cfc9379b9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Metric Mean Score Std Dev\n",
              "0           Accuracy      82.7%    0.9%\n",
              "1          Precision      83.0%    0.9%\n",
              "2             Recall      82.7%    0.9%\n",
              "3  Balanced Accuracy      82.7%    0.9%\n",
              "4           F1 Score      82.7%    0.9%"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e06bddd2-711b-43cf-8137-b09d3e68b3b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Mean Score</th>\n",
              "      <th>Std Dev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>82.7%</td>\n",
              "      <td>0.9%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Precision</td>\n",
              "      <td>83.0%</td>\n",
              "      <td>0.9%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Recall</td>\n",
              "      <td>82.7%</td>\n",
              "      <td>0.9%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Balanced Accuracy</td>\n",
              "      <td>82.7%</td>\n",
              "      <td>0.9%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F1 Score</td>\n",
              "      <td>82.7%</td>\n",
              "      <td>0.9%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e06bddd2-711b-43cf-8137-b09d3e68b3b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e06bddd2-711b-43cf-8137-b09d3e68b3b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e06bddd2-711b-43cf-8137-b09d3e68b3b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95d5d2ce-4e83-47af-8b1d-664db44272db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95d5d2ce-4e83-47af-8b1d-664db44272db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95d5d2ce-4e83-47af-8b1d-664db44272db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4fd7ed94-e3ac-4920-a83a-9e65a408c970\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4fd7ed94-e3ac-4920-a83a-9e65a408c970 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics_df",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Precision\",\n          \"F1 Score\",\n          \"Recall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Score\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"83.0%\",\n          \"82.7%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Std Dev\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.9%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Create a synthetic dataset\n",
        "X, y = make_classification(n_samples=5000, n_features=20, n_informative=10, n_classes=5, n_clusters_per_class=2, flip_y=0, random_state=0)\n",
        "\n",
        "# Set up cross-validation for the test and validation data\n",
        "cv_test = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "cv_valid = StratifiedKFold(n_splits=4, shuffle=True, random_state=0)\n",
        "\n",
        "# Define the parameter grid for KNeighborsClassifier (range of n_neighbors) for tuning hyperparameter, to have ultimate model before testing the validation data\n",
        "# Depending on the validation data\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 10, 12, 15, 40, 100]}\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Set up the GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=cv_valid, scoring='accuracy', return_train_score=True)\n",
        "\n",
        "# Arrays to store results for each fold\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "balanced_accuracy_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Loop through the cross-validation splits\n",
        "for train_valid_index, test_index in cv_test.split(X, y):\n",
        "    X_train_valid, X_test = X[train_valid_index], X[test_index]\n",
        "    y_train_valid, y_test = y[train_valid_index], y[test_index]\n",
        "\n",
        "    # Perform the grid search on the training and validation data\n",
        "    grid_search.fit(X_train_valid, y_train_valid)\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "\n",
        "    # Calculate classification metrics for this split\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
        "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
        "    balanced_accuracy_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Calculate mean and standard deviation for each metric\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'Balanced Accuracy', 'F1 Score'],\n",
        "    'Mean Score': [np.mean(accuracy_scores), np.mean(precision_scores), np.mean(recall_scores), np.mean(balanced_accuracy_scores), np.mean(f1_scores)],\n",
        "    'Std Dev': [np.std(accuracy_scores), np.std(precision_scores), np.std(recall_scores), np.std(balanced_accuracy_scores), np.std(f1_scores)]\n",
        "})\n",
        "\n",
        "# Convert metrics to percentages and round to 1 decimal place\n",
        "metrics_df['Mean Score'] = (metrics_df['Mean Score'] * 100).round(1).astype(str) + '%'\n",
        "metrics_df['Std Dev'] = (metrics_df['Std Dev'] * 100).round(1).astype(str) + '%'\n",
        "\n",
        "metrics_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6s_CiKGNFZ9",
        "outputId": "9c568099-52f2-4748-fdd0-166a4080c0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy on Dataset 1 (High Variance): 0.8480\n",
            "XGBoost Accuracy on Dataset 1 (High Variance): 0.8390\n",
            "Random Forest Accuracy on Dataset 2 (Complex Patterns): 0.8790\n",
            "XGBoost Accuracy on Dataset 2 (Complex Patterns): 0.8924\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Random Forest works better: high variance dataset with noise\n",
        "X1, y1 = make_classification(n_samples=5000, n_features=20, n_informative=5, n_redundant=0, n_repeated=0,\n",
        "                             n_clusters_per_class=1, flip_y=0.3, class_sep=2, random_state=42)\n",
        "\n",
        "# XGBoost works better: dataset with complex interactions and subtle patterns\n",
        "X2, y2 = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0,\n",
        "                             n_clusters_per_class=2, flip_y=0.05, class_sep=0.5, random_state=42)\n",
        "\n",
        "# Train-test split for both datasets\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
        "\n",
        "# Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "# XGBoost model\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "\n",
        "# Evaluate Random Forest on both datasets\n",
        "rf_acc_dataset1 = cross_val_score(rf_model, X1, y1, cv=5, scoring='accuracy').mean()\n",
        "rf_acc_dataset2 = cross_val_score(rf_model, X2, y2, cv=5, scoring='accuracy').mean()\n",
        "\n",
        "# Evaluate XGBoost on both datasets\n",
        "xgb_acc_dataset1 = cross_val_score(xgb_model, X1, y1, cv=5, scoring='accuracy').mean()\n",
        "xgb_acc_dataset2 = cross_val_score(xgb_model, X2, y2, cv=5, scoring='accuracy').mean()\n",
        "\n",
        "# Output the results\n",
        "print(f\"Random Forest Accuracy on Dataset 1 (High Variance): {rf_acc_dataset1:.4f}\")\n",
        "print(f\"XGBoost Accuracy on Dataset 1 (High Variance): {xgb_acc_dataset1:.4f}\")\n",
        "\n",
        "print(f\"Random Forest Accuracy on Dataset 2 (Complex Patterns): {rf_acc_dataset2:.4f}\")\n",
        "print(f\"XGBoost Accuracy on Dataset 2 (Complex Patterns): {xgb_acc_dataset2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxXimtywPyYx"
      },
      "source": [
        "The difference between the two datasets and why **Random Forest** works better on one while **XGBoost** works better on the other can be explained by examining their characteristics.\n",
        "\n",
        "### 1. **Dataset 1 (High Variance, Simple Patterns, Noisy Data)**\n",
        "\n",
        "#### Characteristics:\n",
        "- **Noise**: The `flip_y=0.3` parameter introduces 30% label noise, meaning that 30% of the labels are randomly flipped, making the dataset highly noisy and inconsistent, contributing to high variance.\n",
        "- **Simple relationships**: Only 5 out of the 20 features are informative (`n_informative=5`), and there are no redundant or repeated features (`n_redundant=0, n_repeated=0`). Additionally, there is only 1 cluster per class (`n_clusters_per_class=1`), making the relationships between features and labels relatively simple.\n",
        "- **Class separation**: The `class_sep=2` parameter indicates a high degree of separation between classes, meaning that the different classes are easily distinguishable.\n",
        "\n",
        "#### Why Random Forest Works Better:\n",
        "- **Bagging Reduces Variance**: Random Forest works well with high-variance models by using bagging (Bootstrap Aggregating), which reduces overfitting by averaging multiple decision trees trained on different subsets of the data. This helps smooth out the noise in the dataset.\n",
        "- **Robust to Noise**: Since Random Forest averages predictions from multiple decision trees, it is more robust to noise. Even if individual trees overfit due to the high label noise, the ensemble tends to generalize better.\n",
        "- **Simple Relationships**: Given the simpler relationships between features and labels (due to fewer informative features and only one cluster per class), Random Forest captures the patterns effectively without overcomplicating the model.\n",
        "\n",
        "#### Conclusion:\n",
        "Random Forest performs better in **high-variance, noisy datasets** with simpler patterns, where its ability to average predictions across independent trees helps mitigate the noise and variance.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Dataset 2 (Complex Patterns, Low Noise)**\n",
        "\n",
        "#### Characteristics:\n",
        "- **Complex relationships**: This dataset has more informative features (`n_informative=10`), which means there are more meaningful and complex patterns between the features and the target labels. There are also two clusters per class (`n_clusters_per_class=2`), further increasing the complexity of the relationships.\n",
        "- **Low noise**: The `flip_y=0.05` parameter introduces only 5% label noise, meaning that the relationships between features and labels are more consistent and less prone to random fluctuations.\n",
        "- **Subtle class separation**: The `class_sep=0.5` parameter indicates that the separation between classes is more subtle, requiring the model to capture nuanced relationships between features to make accurate predictions.\n",
        "\n",
        "#### Why XGBoost Works Better:\n",
        "- **Boosting Reduces Bias**: XGBoost is a boosting method that focuses on reducing bias by sequentially improving weak learners. It works well when there are complex patterns to uncover because it refines the model iteratively by focusing on the hardest-to-classify examples.\n",
        "- **Handling Complex Patterns**: XGBoost is particularly well-suited for datasets with more informative features and subtle class separations. Its iterative approach helps capture the deeper relationships in the data.\n",
        "- **Low Noise**: XGBoost is more prone to overfitting in highly noisy datasets, but here, the low noise allows it to focus on capturing the complex patterns without being distracted by random noise.\n",
        "\n",
        "#### Conclusion:\n",
        "XGBoost performs better in **datasets with complex patterns and low noise**, where its sequential approach to refining the model allows it to capture subtle relationships between features and target labels.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of Differences:\n",
        "\n",
        "| Dataset                   | Characteristics                                          | Why Random Forest Works Better           | Why XGBoost Works Better                 |\n",
        "|---------------------------|----------------------------------------------------------|------------------------------------------|------------------------------------------|\n",
        "| **Dataset 1 (High Variance, Noisy)**  | High noise (`flip_y=0.3`), few informative features, simple class separation (`class_sep=2`) | Reduces variance and handles noise effectively by averaging multiple models | Prone to overfitting to noisy data       |\n",
        "| **Dataset 2 (Complex Patterns, Low Noise)** | Low noise (`flip_y=0.05`), more informative features, subtle class separation (`class_sep=0.5`) | Independent trees struggle to capture complex patterns | Captures complex relationships through iterative refinement |\n",
        "\n",
        "### Key Takeaways:\n",
        "- **Random Forest** works better on high-variance, noisy datasets with simpler relationships by reducing variance through bagging, making it more robust to noisy data.\n",
        "- **XGBoost** excels in datasets with complex patterns and low noise, where it can iteratively reduce bias and improve performance by focusing on harder-to-classify instances.\n",
        "\n",
        "In this case:\n",
        "- **Random Forest performs better on Dataset 1**, which has high noise, few informative features, and simple class separation.\n",
        "- **XGBoost performs better on Dataset 2**, which has low noise, more informative features, and complex relationships between features and classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChT3kpKjjPw-"
      },
      "source": [
        "# Excercise!\n",
        "\n",
        "For the same datasets above, create a nested cross validation pipeline and then compare the results for XGBoost and RandomForest classifiers (with proper hyper-parameter tuning)\n",
        "\n",
        "\n",
        "```python\n",
        "# Random Forest works better: high variance dataset with noise\n",
        "X1, y1 = make_classification(n_samples=5000, n_features=20, n_informative=5, n_redundant=0, n_repeated=0,\n",
        "                             n_clusters_per_class=1, flip_y=0.3, class_sep=2, random_state=42)\n",
        "\n",
        "# XGBoost works better: dataset with complex interactions and subtle patterns\n",
        "X2, y2 = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0,\n",
        "                             n_clusters_per_class=2, flip_y=0.05, class_sep=0.5, random_state=42)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Datasets\n",
        "X1, y1 = make_classification(n_samples=5000, n_features=20, n_informative=5, n_redundant=0, n_repeated=0,\n",
        "                             n_clusters_per_class=1, flip_y=0.3, class_sep=2, random_state=42)\n",
        "X2, y2 = make_classification(n_samples=5000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0,\n",
        "                             n_clusters_per_class=2, flip_y=0.05, class_sep=0.5, random_state=42)\n",
        "\n",
        "# Models and hyperparameter grids\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
        "\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "xgb_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.3]}\n",
        "\n",
        "\n",
        "def nested_cv(X, y, model, param_grid):\n",
        "  outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "  outer_scores = []\n",
        "\n",
        "  for train_index, test_index in outer_cv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=inner_cv, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    outer_scores.append(accuracy_score(y_test, grid_search.predict(X_test)))\n",
        "  return np.mean(outer_scores)\n",
        "\n",
        "# Evaluate models using nested cross-validation\n",
        "rf_score_dataset1 = nested_cv(X1, y1, rf_model, rf_param_grid)\n",
        "xgb_score_dataset1 = nested_cv(X1, y1, xgb_model, xgb_param_grid)\n",
        "\n",
        "rf_score_dataset2 = nested_cv(X2, y2, rf_model, rf_param_grid)\n",
        "xgb_score_dataset2 = nested_cv(X2, y2, xgb_model, xgb_param_grid)\n",
        "\n",
        "# Output results\n",
        "print(f\"Random Forest Accuracy (Dataset 1): {rf_score_dataset1:.4f}\")\n",
        "print(f\"XGBoost Accuracy (Dataset 1): {xgb_score_dataset1:.4f}\")\n",
        "print(f\"Random Forest Accuracy (Dataset 2): {rf_score_dataset2:.4f}\")\n",
        "print(f\"XGBoost Accuracy (Dataset 2): {xgb_score_dataset2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HBQttKcGGEi",
        "outputId": "33e0a7ca-c173-4fab-fb76-69bfcc2069b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy (Dataset 1): 0.8480\n",
            "XGBoost Accuracy (Dataset 1): 0.8466\n",
            "Random Forest Accuracy (Dataset 2): 0.8820\n",
            "XGBoost Accuracy (Dataset 2): 0.8944\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}